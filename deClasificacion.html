<!DOCTYPE HTML>
<!--
Editorial by HTML5 UP
html5up.net | @ajlkn
Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
<head>
<title>De Clasificación </title>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
<link rel="stylesheet" href="assets/css/main.css" />
</head>
<body class="is-preload">

<!-- Wrapper -->
<div id="wrapper">

<!-- Main -->
	<div id="main">
		<div class="inner">

			<!-- Header -->
				<header id="header">
					<a href="index.html" class="logo"></a>
					<ul class="icons">
							<li><a href="https://github.com/leticia8/portofliollado" class="icon brands fa-github"><span class="label">Git Hub</span></a></li>
					<li><a href="https://www.linkedin.com/in/leticia-lado-50b7a5106/" class="icon brands fa-linkedin"><span class="label">Linked In</span></a></li>
			</ul>
				</header>
				
			<!-- Content -->
				<section>
					<header class="main">
						<h1>Algoritmos de clasificación</h1>
					</header>

					<span class="image main"><img src="images/supClas.png" style="width:60%;height:80%;" alt="" /></span>

					<p>Los problemas de clasificación son aquellos en los que la variable de salida es una clase categórica como "rojo" o "verde", "alto" y "bajo". Algunos
					algoritmos presentan mejores performances para clases binominales mientras que otros sirven para múltiples clases.</p>
					Entre los algoritmos más utilizados de clasificación se encuentran: </p>



				<p style="font-size:24px ;color:Tomato;" > REGRESIÓN LOGÍSTICA </p>
							<p style="font-size:18px ;text-align:justify" >
							Es un algoritmo para problemas de clasificación binaria, es decir su salida determina la pertenencia o no a una clase.
							El algoritmo utiliza una función sigmoidea que resulta en una curva con forma de S que puede tomar cualquier valor real y 
							mapearlo en valores de 0 a 1 pero nunca exactamente esos valores.
							Modela la probabilidad de la clase por defecto , es decir, la probabilidad de que un valor de entrada X pertenezca a la clase por defecto Y=1:
									<img src="http://latex.codecogs.com/gif.latex?P(X)=P(Y=1|X)" border="0"/>. <br>

							Es un método lineal, pero las predicciones se transforman utilizando la función logística, mientras que por medio de la estimación de máxima verosimilitud 
							se calculan los coeficientes del algoritmo.<br><br>
							<strong>PREPARACIÓN DATOS: </strong><br>
							Remover ruido<br>
							Asegurar distribución Gaussiana: Asume relacion lineal entre variables<br>
							Remover variables de entrada correlacionadas o si la infomación está muy diferenciada puede fallar en converger.<br>
							También puede tener baja performance al haber pocos datos.</p>
							
							
							<p style="font-size:24px ;color:Tomato;" >ANÁLISIS DEL DISCRIMINANTE LINEAL</p>

							<p style="font-size:18px ;text-align:justify" >Si tenemos más de dos clases, es la técnica de clasificación preferida, también se puede aplicar con problemas de clasificación binaria.<br>
							Para cada clase se calculan descriptores estadísticos, para una variable única de entrada estos pueden ser media y varianza para cada clase. 
							Para muchas variables se utilizan matrices de medias y de covarianza.<br>
							El método LDA asume que los datos tienen distribución normal y cada atributo tiene la misma varianza.<br>
							Se calcula la suma de las diferencias al cuadrado de cada valor a la media dentro de la clase de referencia, pero se realiza el promedio usando como referencia todos los grupos.<br>
							LDA predice estimando la probabilidad de que un nuevo set de puntos pertenezcan a cada clase. 
							La clase que obtiene la probabilidad mayor es la clase de saluda. El algoritmo utiliza el teorema de Bayes para estimar esas probabilidades.<br><br>
								<strong>PREPARACIÓN DATOS: </strong><br>
							Soporta clasificaciones binarias y multiclase.<br>
							Distribución normal: la implementación normal asume distribución normal para las variables de entrada.<br>
							Remover outliers:<br>
							Misma varianza: LDA assume que cada variable de entrada tiene la misma varianza. Es bueno estandarizar los datos con media 0 y varianza 1 antes de aplicar el algoritmo.<br>

							<p style="font-size:24px ;color:Tomato;" >SUPPORT VECTOR MACHINE - SVM</p>

							<p style="font-size:18px ;text-align:justify" >Se selecciona el hiperplano que mejor separa los puntos en el espacio de variables de entrada. 
							Podría visualizarse como una línea, y se asume que todos los valores de las variables de entrada pueden ser completamente separados por esta línea.<br>
							Usando esta línea se puede determinar si un nuevo punto a clasificar está por encima o por debajo de la línea según si retorna valores positivos o negativos; en el primer caso devuelve el valor 0 y en el segundo 1.
							Un valor cercano a la línea puede ser difícil de clasificar.<br>
							El margen se calcula como la distancia ortogonal a la línea para los puntos más cercanos. Sólo estos puntos son relevantes para definir la línea y para construir el clasificador. Estos puntos se llaman vectores de soport y definen el hiperplano.<br>
							
							Hay una adaptación que suaviza lo estricto del margen, permitiendo que algunos puntos violen la separación de la línea. Se define un parámetro de tuneo C que refiere a la cantidad de puntos que se tolera violen ese margen. Un C=0 implica ninguna violación
							y es el que adopta el método Maximal-Margin Classifier. Cuanto más pequeño el valor de C, el algoritmo es más sensible a valores de entrenamiento.<br>
							<strong>KERNEL SVM: </strong><br>
							En la práctima el algoritmo se implementa usando un kernel o núcleo. Dicha función Kernel puede ser:
							Lineal:<br>
							<img src="http://latex.codecogs.com/gif.latex?K(x, x_i)=\sum(x * x_i)" border="0"/>. <br>
							Polinomial:<br>
									<img src="http://latex.codecogs.com/gif.latex?K(x,x_i) = 1 + \sum(x * x_i)^d" border="0"/>. <br>
							 
							
							Radial:<br>
							<img src="http://latex.codecogs.com/gif.latex?K(x,x_i) = e ^ {-gamma *\sum(x * x_i^2)}" border="0"/>. <br><br>
						
							<strong>PREPARACIÓN DATOS: </strong><br>
							Los valores de las variables de entrada deben ser numéricos, si son categóricas habrá que transformarlas a variables dummy (valor 1 - 0).
							Es un método pensado idealmente para clasificación binaria.</p>
							
							<p style="font-size:24px ;color:Tomato;" >NAIVE BAYES</p>
							<p style="font-size:18px ;text-align:justify" >El teorema de Naive Bayes se basa en la utilización del conocimiento previo que posee el investigador sobre cierto tema.
							El teorema de Bayes es:<br><br>
							<img src="http://latex.codecogs.com/gif.latex?P(h|d) = \frac{P(d|h) * P(h)}{P(d)}" border="0"/>. <br><br>
							

							Donde:
							P(h│d) es la probabilidad de una hipótesis h dada la información d. A esto se le llama probabilidad a posteriori.<br>
							P(d│h) es la probabilidad de la información d dado que la hipótesis h es cierta.<br>
							P(h) es la probabilidad de la hipótesis h sea cierta. Es la probabilidad a priori.<br>
							P(d) es la probabilidad de la información<br>

							Naive Bayes es un algoritmo de clasificación para problemas binarios y multiclase. La técnica es la más fácil de entender cuando se describe usando variables binarias o categóricas.<br>
							Los valores de probabilidad de cada atributo se asumen condicionalmente independientes dado el valor objetivo a calcular.<br>
							La representación del método Naive Bayes es una lista de probabilidades almacenados que incluye probabilidades de clase y probabilidades condicionales.<br>
							El entrenamiento es rápido porque sólo la probabilidad de cada clase y la de cada clase dado el valor de entrada debe calcularse, no se precisa ajustar coeficientes ni procedimientos de optimización.<br>
							El algoritmo puede ser extendido a atributos reales, asumiendo distribuciones normales, también pueden utilizarse otras funciones de distribución pero la distribución gaussiana es la forma más fácil de trabajar porque sólo precisa estimar media y desviación estándar.<br><br>
							<strong>PREPARACIÓN DATOS: </strong><br>
							Variables de entrada categóricas: asume que los atributos a estimar son binarios, categóricos o nominales.
							Distribución normal: si las variables de entrada son reales se asume distribuciónón normal.
							Algoritmo de clasificación que sirve para clasificar en dos o más clases.
							Probabilidades logarítmicas: es útil realizar una transformación logarítmica de las probabilidades con el fin de evitar desbordamiento de precisión.
							Para diferentes distribuciones de los datos se pueden utilizar distribuciones más complejas así como una variedad de funciones de densidad del núcleo(kernel).</p>


							<p style="font-size:24px ;color:Tomato;" > ÁRBOLES DE DECISIÓN - 	CART – Classification And Regression Trees </p>
							<p style="font-size:18px ;text-align:justify" >Clásicamente se han referido como árboles de decisión aunque actualmente se los nombre como Classification and Regression Trees (CART)<br>
						
							La representación es un árbol binario donde cada nodo representa una variable de entrada x y un punto de corte en dicha variable. Las hojas del árbol contienen la variable de salida (y) que son usadas para hacer la predicción.<br>
							Hacer predicciones es bastante directo. 
							Se puede pensar a cada variable de entrada como una dimensión en un espacio p-dimensional. 
							El árbol de decisión divide el espacio en dos rectángulos o hiper-rectángulos con más entradas.<br>
							Se usa un método ávido dividir el espacio denominado división recursiva binaria. 
							Es un procedimiento numérico donde todos los valores se alinean y diferentes puntos de división se prueban usando una función de costo. 
							La división con mejor costo es seleccionada. <br>
							
							Para problemas de clasificación el costo de Gini es usado y provee una indicación de cuán puros son los nodos, los valores cercanos a 0 tienen todas las clases del mismo tipo.<br>
							Para algoritmos de clasificación como en bagging cada árbol vota y la proporción de votos en cada clase es el error probabilístico estimado.<br>
							El procedimiento de detención más común es usar la mínima cantidad de datos de entrenamiento usados para cada nodo hoja.<br>
							Se puede podar el árbol luego del entrenamiento dado que árboles más sencillos son preferidos dado que son más fáciles de entender y menos probable de que sobreajusten la información.<br>
							Los métodos de poda más rápidos y sencillos se llevan a cabo evaluando el efecto sobre el costo de remover dicho nodo del modelo.
							Cuando no se logran mejoras se detiene el procedimiento.<br><br>
							<strong>PREPARACIÓN DATOS: </strong><br>
							No require preparación.<br></p>

							
							<p style="font-size:24px ;color:Tomato;" >RANDOM FOREST</p>
							<p style="font-size:18px ;text-align:justify"> Son una mejora sobre los árboles de decisión que utilizan el algoritmo Bagged (Bagging and Aggregation).
							El problema es que es un algoritmo ávido, esto implica que en cada iteración busca el óptimo local que puede terminar no siendo el óptimo a nivel general.
							En cada split se evalúa un número de atributos establecidos por parámetro que son seleccionados aleatoriamente de entre todos los atributos disponibles,
							Para problemas de clasificación se aconseja utilizar la raíz cuadrada del número de predictores como parámetro que determina cuántos atributos aleatorios seleccionar.<br>  
							Random Forest soluciona el problema de la correlación entre los modelos al incluir aleatoriedad en la elaboración de los mismos.
							Para decidir la cantidad m de atributos a seleccionar es mejor iniciar con 5 valores entre 2 y p (cantidad de atributos o variables de entrada) e ir probando la performance, para la cantidad de modelos a ejecutar
							se recomienda un aproximado a 1000 árboles aunque como en todos los casos depende del problema y el conocimiento del negocio. <br>
							En random forest todos los árboles se crean independientemente para tener la profundidad deseada y contribuye de igual forma al modelo.<br>
							
								</p>
						




					<hr class="major" />

								<h2>Proyectos que utilizan métodos de clasificación</h2>
						<ul>
										<li><a href="proyectoDos.html">Predicción cardiológica</a></li>
									</ul>
					<h2> </h2>
					

				</section>

		</div>
	</div>

	<!-- Sidebar -->
		<div id="sidebar">
			<div class="inner">

				<!-- Search -->
					<section id="search" class="alt">
						<form method="post" action="#">
							<input type="text" name="query" id="query" placeholder="Search" />
						</form>
					</section>
	<!-- Menu -->
		<nav id="menu">
			<header class="major">
				<h2>Menu</h2>
			</header>
			<ul>
				<li><a href="index.html">Inicio</a></li>
				<li><a href="introduccion.html">Introducción a Machine Learning </a></li>
				<li>
					<span class="opener" href="index.html">Marco teórico</span>
					<ul>
						<li><a  href="supervisados.html">Aprendizaje Supervisado</a></li>
						<ul>
						<li><a href="deRegresion.html">De regresión</a></li>
						<li><a href="deClasificacion.html">De clasificación</a></li>
						</ul>
						<li><a  href="noSupervisados.html">Aprendizaje no supervisados</a></li>
						<ul>
						<li><a href="deClustering.html">De Clustering</a></li>
						<li><a href="deReduccionDim.html">De reducción de dimensiones</a></li>
						
						</ul>
					</ul>
				</li>
				<li>
					<span class="opener" href="proyectos.html">Proyectos Analizados</span>
					<ul>
						<li><a href="proyectoUno.html">Predicción precios de viviendas  </a></li>
						<li><a href="proyectoDos.html">Predicción cardiológica</a></li>
					
						<li><a href="proyectoCuatro.html">Predicción altura a partir de restos óseos</a></li>
						<li><a href="proyectoTres.html">Predicción pacientes con/sin hígado</a></li>
						<li><a href="proyectoCinco.html">Predicción de autismo en adultos</a></li>
				
			

					</ul>
				</li>
				<li><a href="TAS.html">TA's del curso</a></li>
			
			</ul>
		</nav>

		
			
		</div>
	</div>

</div>

						</div>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>