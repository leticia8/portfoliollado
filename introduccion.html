<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Marco teórico Machine Learning </title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
								<header id="header">
									<ul class="icons">
											<li><a href="https://github.com/leticia8/portofliollado" class="icon brands fa-github"><span class="label">Git Hub</span></a></li>
									<li><a href="https://www.linkedin.com/in/leticia-lado-50b7a5106/" class="icon brands fa-linkedin"><span class="label">Linked In</span></a></li>
							</ul>
								</header>
								
							<!-- Content -->
								<section>
									<header class="main">
										<h1>Introducción a Machine Learning</h1>
									</header>

									<span class="image main"><img src="images/ML1.png" style="width:40%;height:30%px;" alt="" /></span>

									<p></p>

									<hr class="major" />

									<h2> </h2>
									<p style="font-size:20px ;text-align:justify" >Entre las diversas definiciones de Machine Learning que uno puede encontrar al realizar una búsqueda en internet se pueden identificar: <br><br>
										“Machine Learning es una disciplina científica del ámbito de la Inteligencia Artificial que crea sistemas que aprenden automáticamente. Aprender en este contexto quiere decir identificar patrones complejos en millones de datos. La máquina que realmente aprende es un algoritmo que revisa los datos y es capaz de predecir comportamientos futuros. Automáticamente, también en este contexto, implica que estos sistemas se mejoran de forma autónoma con el tiempo, sin intervención humana. Veamos cómo funciona.” 	<br><br>
										 “El aprendizaje automático es un campo de la informática que tiene como objetivo enseñar a las computadoras cómo aprender y actuar sin ser programado explícitamente. Más específicamente, el aprendizaje automático es un enfoque para el análisis de datos que implica construir y adaptar modelos, que permiten a los programas "aprender" a través de la experiencia. El aprendizaje automático implica la construcción de algoritmos que adaptan sus modelos para mejorar su capacidad de hacer predicciones.” 	<br><br>
										“Los algoritmos de aprendizaje automático utilizan estadísticas para encontrar patrones en cantidades masivas de datos. Y los datos, aquí, abarcan muchas cosas: números, palabras, imágenes, clics, lo que tienes. Si se puede almacenar digitalmente, se puede alimentar a un algoritmo de aprendizaje automático. El aprendizaje automático es el proceso que impulsa muchos de los servicios que usamos hoy en día: sistemas de recomendación como los de Netflix, YouTube y Spotify; motores de búsqueda como Google y Baidu; feeds de redes sociales como Facebook y Twitter; Asistentes de voz como Siri y Alexa.”	<br>
									<h2> Machine learning e Inteligencia Artificial</h2>
									<img src="images/machineLearning.png" style="width:40%;height:40%;" alt="" />
									<p style="font-size:20px ;text-align:justify" >Machine learning es un área o rama de la inteligencia artificial, dado que los algoritmos de machine learning sirven como herramienta para llevar a cabo procesos de inteligencia artificial. 
									
									
									</p>
									
									<h2>Machine learning y análisis estadístico</h2>
									<img src="images/mlyest.jpg" style="width:40%;height:40%;" alt="" />
									<p style="font-size:20px ;text-align:justify" >En cuanto al análisis estadístico los campos de acción de ambas disciplinas son complementarios, incluso los modelos utilizados en los algoritmos de Machine Learning son modelos estadísticos. A su vez los algoritmos de machine learning potencian cualquier análisis estadístico al automatizar procesos que de otro medio no serían viables o serían tediosos como puede ser encontrar relaciones causales entre variables y sus correlaciones así como inferir posibles relaciones ocultas.</p>
									
									<h2>Machine learning y data mining</h2>
									<p style="font-size:20px ;text-align:justify" >Machine learning usa técnicas de data mining así como de la estadística para explorar patrones subyacentes y construir modelos sobre el vínculo de los datos, el data mining extrae reglas de los datos mientras que el machine learning se encarga de generar un proceso automático para el aprendizaje de dichas reglas y la construcción de modelos que permitan explicar y/o predecir el comportamiento de los datos y las relaciones causales entre variables.</p>
									
									<h2>	Aplicaciones de machine learning</h2>
									<p style="font-size:20px ;text-align:justify" >Las aplicaciones de machine learning son transversales a todas las áreas de conocimiento, sin dudas hay áreas más sensibles como la seguridad (tanto a nivel de protección de datos como análisis de fraude) y el ámbito financiero donde la implementación de métodos rápidos y eficientes implica un salto cualitativo porque no se pueden permitir demoras en la toma de decisiones y análisis de la información. Otras áreas relevantes son el marketing, las aseguradoras, el ámbito de la salud así como también las áreas de procesamiento de lenguaje natural y algunos avances dentro del área de Internet of Things como autos inteligentes, entre otros.</p>
									
									<h2>CRISP - DM</h2>
									<img src="images/crisp-dm.png" style="width:40%;height:40%;" alt="" />
								<p style="font-size:20px ;text-align:justify" >CRISP-DM (Cross Industry Standard Process for Data Mining) sintetiza el ciclo de vida de un proyecto de análisis de datos, dividiéndolo en seis fases principales que no son rígidas sino que permiten el avance hacia atrás y hacia adelante en la medida que las necesidades así lo dispongan.<br><br>
									Las<strong> seis</strong> fases del proceso son: <br>
									<strong>1.	Comprensión del negocio. (Business Understanding).</strong> Definición de necesidades del cliente <br>
									<strong>2.	 Comprensión de los datos (Data Understanding)</strong>: Familiarización con los datos para conocerlos, identificando problemas de calidad y realizando hipótesis de posibles correlaciones.<br>
									<strong>3.	Preparación de los datos</strong>:  selección de tablas,  atributos, transformación y limpieza de datos, tratamiento de missing.<br>
									<strong>4.	Modelado</strong>: selección técnicas de modelado y ajuste de parámetros. <br>
									<strong>5.	Evaluación del modelo</strong>, se revisan los pasos seguidos para crearlo y cuánto se adapta al negocio.<br>
									<strong>6.	Implantación</strong> implica la organización de la información, su presentación y disposición para poder transmitir al cliente.<br><br>
									Este proceso es aún utilizado pero también se le critica que es un proceso diseñado hace muchos años que ha perdido vigencia, en su lugar surgen procesos más ágiles que buscan una retroalimentación a medida que avanzan en las etapas, este es el caso de Team Data Science Process es un modelo dinámico que se basa en cuatro etapas: Entendimiento del negocio, Adquisición y entendimiento de los datos, Modelado, Implantación, algunos incluyen una quinta etapa que requeriría la aceptación del cliente. Está ortientado al trabajo en equipo y colaborativo.<br><br>
									
									Procesos análogos son <strong>KDD </strong>acrónimo de Knowledge Discovery in Databases :<br>
									<img src="images/kdd.png" style="width:40%;height:40%;" alt="" /><br><br>
									Consta de <strong> cinco </strong>etapas <br>
									<strong>Selección: </strong>crear un data set objetivo o focalizarse en un subset de variables o muestras de información.<br>
									<strong>Pre-procesamiento: </strong>limpieza de los datos para que sea consistentes<br>
									<strong>Tansformación:</strong> transformación de los datos usando la reducción o transformación<br>
									<strong>Data Mining:</strong> buscar patrones de interés dependiendo los objetivos buscandos.<br>
									<strong>Interpretación/Evaluación:</strong> interpretación y evaluación de los patrones obtenidos.<br><br>
									

									<br>
									<br>
									
								<strong>	SEMMA </strong>: impulsado por el SAS Institute y acrónimo de Sample, Explore, Modify, Model, and Assess consta de cinco etapas:<br>
																				<img src="images/semma.JPG" style="width:40%;height:40%;" alt="" /><br>
									<strong>Muestra </strong>, selección de datos, que debe ser lo suficientemente grande como para obtener la información necesitada y lo suficientemente pequeña como para poder ser usada eficientemente.<br>
									<strong>Exploración</strong>, cubre el entendimiento de los datos descubriendo relaciones entre variables así como cualquier anormalidad.<br>
									<strong>Modificación:</strong> contiene métodos para seleccionar, crear y transformar variables para preparar el modelado de datos<br>
									<strong>Modelado:</strong> en esta fase el foco está en aplicar varias técnicas de modelo en las variables preparadas para crear modelos deseados.<br>
									<strong>Evaluación: </strong>ultima fase en la que se evalúa el modelo y se muestra la utilidad y fiabilidad del modelo.<br>
									KDD y SEMMA pueden verse como procesos análogos con etapas equivalentes, mientras que el CRISP-DM  incorpora pasos previos y posteriores de los anteriores procesos, como ser el conocimiento del negocio y le implementación.</p>

								</section>

						</div>
					</div>

				<!-- Sidebar -->
					<div id="sidebar">
						<div class="inner">

							<!-- Search -->
								<section id="search" class="alt">
									<form method="post" action="#">
										<input type="text" name="query" id="query" placeholder="Search" />
									</form>
								</section>
														
<!-- Menu -->
		<nav id="menu">
			<header class="major">
				<h2>Menu</h2>
			</header>
			<ul>
				<li><a href="index.html">Inicio</a></li>
				<li><a href="introduccion.html">Introducción a Machine Learning </a></li>
				<li>
					<span class="opener" href="index.html">Marco teórico</span>
					<ul>
						<li><a  href="supervisados.html">Aprendizaje Supervisado</a></li>
						<ul>
						<li><a href="deRegresion.html">De regresión</a></li>
						<li><a href="deClasificacion.html">De clasificación</a></li>
						</ul>
						<li><a  href="noSupervisados.html">Aprendizaje no supervisados</a></li>
						<ul>
						<li><a href="deClustering.html">De Clustering</a></li>
						<li><a href="deReduccionDim.html">De reducción de dimensiones</a></li>
						
						</ul>
					</ul>
				</li>
				<li>
					<span class="opener" href="proyectos.html">Proyectos Analizados</span>
					<ul>
						<li><a href="proyectoUno.html">Predicción precios de viviendas  </a></li>
						<li><a href="proyectoDos.html">Predicción cardiológica</a></li>
						<li><a href="proyectoTres.html">Predicción pacientes con/sin hígado</a></li>
						<li><a href="proyectoCuatro.html">Predicción altura a partir de restos óseos</a></li>
						
						<li><a href="proyectoCinco.html">Predicción de autismo en adultos</a></li>
				
						<li><a href="proyectoSeis.html">Nombre 6</a></li>

					</ul>
				</li>
				<li><a href="TAS.html">TA's del curso</a></li>
			
			</ul>
		</nav>

		
			
		</div>
	</div>

</div>


		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>